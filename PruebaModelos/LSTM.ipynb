{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22faefcf",
   "metadata": {},
   "source": [
    "## Proyecto 3. Entrega 3\n",
    "### LSTM\n",
    "Diego Duarte 22075 - José Marchena 22398 - Andrés Kou 22305 - Esteban Zambrano 22119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061b56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import LSTM\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "csv_path = \"../DataFinal.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 3, 20)\n",
      "(114,)\n",
      "[[[27.0 194 10.0 ... 0.0 36.0 0.0]\n",
      "  [119.0 2629 767.0 ... 846.0 432.0 131.0]\n",
      "  [368.0 5587 3805.0 ... 3871.0 897.0 486.0]]\n",
      "\n",
      " [[119.0 2629 767.0 ... 846.0 432.0 131.0]\n",
      "  [368.0 5587 3805.0 ... 3871.0 897.0 486.0]\n",
      "  [478.0 5712 5380.0 ... 5335.0 997.0 645.0]]\n",
      "\n",
      " [[368.0 5587 3805.0 ... 3871.0 897.0 486.0]\n",
      "  [478.0 5712 5380.0 ... 5335.0 997.0 645.0]\n",
      "  [438.0 4716 4841.0 ... 4753.0 995.0 572.0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[638.0 5970 5201.0 ... 5659.0 513.0 405.0]\n",
      "  [613.0 5274 5236.0 ... 5652.0 662.0 494.0]\n",
      "  [581.0 4103 4501.0 ... 4757.0 627.0 533.0]]\n",
      "\n",
      " [[613.0 5274 5236.0 ... 5652.0 662.0 494.0]\n",
      "  [581.0 4103 4501.0 ... 4757.0 627.0 533.0]\n",
      "  [546.0 2957 3455.0 ... 3566.0 669.0 504.0]]\n",
      "\n",
      " [[581.0 4103 4501.0 ... 4757.0 627.0 533.0]\n",
      "  [546.0 2957 3455.0 ... 3566.0 669.0 504.0]\n",
      "  [395.0 1757 2163.0 ... 2250.0 455.0 338.0]]]\n"
     ]
    }
   ],
   "source": [
    "n_lags = 3  # Usaremos los 3 años previos\n",
    "X, y = LSTM.preparar_series_lstm(df, n_lags)\n",
    "\n",
    "# Revisar las dimensiones de X e y\n",
    "print(X.shape)  # Esto debería ser (n_samples, 3, n_features)\n",
    "print(y.shape) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 3, 20) (23, 3, 20)\n",
      "(91,) (23,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir en entrenamiento y prueba (sin mezclar las secuencias)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=61023521)\n",
    "\n",
    "# Ver las formas de los datos\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a29a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a325b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizar X_train, X_test, y_train, y_test\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n",
    "X_test_scaled = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1]))\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Convertir los datos normalizados a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).view(-1, X_train.shape[1], X_train.shape[2])\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).view(-1, X_test.shape[1], X_test.shape[2])\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Crear dataloaders\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5f212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "input_size = X_train.shape[2]  # El número de características (columnas de VI)\n",
    "hidden_size = 64  # Puedes ajustar este valor\n",
    "num_layers = 2  # Puedes ajustar este valor\n",
    "\n",
    "# Inicializar el modelo\n",
    "model = LSTM.LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "# Definir la función de pérdida (MSE) y el optimizador (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0628efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.0159\n",
      "Epoch [2/50], Loss: 0.9633\n",
      "Epoch [3/50], Loss: 0.9076\n",
      "Epoch [4/50], Loss: 0.8399\n",
      "Epoch [5/50], Loss: 0.7531\n",
      "Epoch [6/50], Loss: 0.6438\n",
      "Epoch [7/50], Loss: 0.5162\n",
      "Epoch [8/50], Loss: 0.3890\n",
      "Epoch [9/50], Loss: 0.2926\n",
      "Epoch [10/50], Loss: 0.2340\n",
      "Epoch [11/50], Loss: 0.1745\n",
      "Epoch [12/50], Loss: 0.1108\n",
      "Epoch [13/50], Loss: 0.0709\n",
      "Epoch [14/50], Loss: 0.0556\n",
      "Epoch [15/50], Loss: 0.0461\n",
      "Epoch [16/50], Loss: 0.0333\n",
      "Epoch [17/50], Loss: 0.0236\n",
      "Epoch [18/50], Loss: 0.0214\n",
      "Epoch [19/50], Loss: 0.0208\n",
      "Epoch [20/50], Loss: 0.0184\n",
      "Epoch [21/50], Loss: 0.0164\n",
      "Epoch [22/50], Loss: 0.0149\n",
      "Epoch [23/50], Loss: 0.0130\n",
      "Epoch [24/50], Loss: 0.0113\n",
      "Epoch [25/50], Loss: 0.0105\n",
      "Epoch [26/50], Loss: 0.0100\n",
      "Epoch [27/50], Loss: 0.0095\n",
      "Epoch [28/50], Loss: 0.0089\n",
      "Epoch [29/50], Loss: 0.0084\n",
      "Epoch [30/50], Loss: 0.0080\n",
      "Epoch [31/50], Loss: 0.0076\n",
      "Epoch [32/50], Loss: 0.0073\n",
      "Epoch [33/50], Loss: 0.0070\n",
      "Epoch [34/50], Loss: 0.0068\n",
      "Epoch [35/50], Loss: 0.0066\n",
      "Epoch [36/50], Loss: 0.0064\n",
      "Epoch [37/50], Loss: 0.0063\n",
      "Epoch [38/50], Loss: 0.0061\n",
      "Epoch [39/50], Loss: 0.0059\n",
      "Epoch [40/50], Loss: 0.0058\n",
      "Epoch [41/50], Loss: 0.0056\n",
      "Epoch [42/50], Loss: 0.0055\n",
      "Epoch [43/50], Loss: 0.0054\n",
      "Epoch [44/50], Loss: 0.0053\n",
      "Epoch [45/50], Loss: 0.0052\n",
      "Epoch [46/50], Loss: 0.0051\n",
      "Epoch [47/50], Loss: 0.0050\n",
      "Epoch [48/50], Loss: 0.0049\n",
      "Epoch [49/50], Loss: 0.0048\n",
      "Epoch [50/50], Loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Número de épocas\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Establecer el modelo en modo entrenamiento\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Enviar los datos a GPU si está disponible\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Reiniciar los gradientes de los optimizadores\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Hacer una predicción\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calcular la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Propagar hacia atrás (backpropagation)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualizar los parámetros\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb07bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [[ 0.5827416 ]\n",
      " [-0.18729548]\n",
      " [-0.7459477 ]\n",
      " [-1.0072562 ]\n",
      " [-1.0715834 ]]\n",
      "Valores reales: [[ 0.35792658]\n",
      " [-0.29539424]\n",
      " [-0.8298666 ]\n",
      " [-1.041411  ]\n",
      " [-1.0556492 ]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Establecer el modelo en modo evaluación\n",
    "with torch.no_grad():  # No necesitamos calcular los gradientes durante la evaluación\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Hacer predicción\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Almacenar las predicciones y los valores verdaderos\n",
    "        y_pred.append(outputs.cpu().numpy())\n",
    "        y_true.append(labels.cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "# Comparar las predicciones con los valores verdaderos\n",
    "print(f\"Predicciones: {y_pred[:5]}\")\n",
    "print(f\"Valores reales: {y_true[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe99638",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a2d2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 200) (85,)\n",
      "(22, 200) (22,)\n"
     ]
    }
   ],
   "source": [
    "# Juntar la data de los ultimos años\n",
    "X_all, y_all = LSTM.preparar_series_lstm(df, 10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, \n",
    "    test_size=0.2, \n",
    "    shuffle=False, \n",
    "    random_state=61023521)\n",
    "X_train = X_train.reshape(85,-1)\n",
    "X_test = X_test.reshape(22,-1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ed49366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from pipeline import crear_pipeline_svm\n",
    "\n",
    "svm = crear_pipeline_svm(SVR(kernel='linear'))\n",
    "svm.fit(X_train, y_train)\n",
    "y_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82eb1f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR:\n",
      "MAE: 28173.901243124154\n",
      "MSE: 1047549304.3330089\n",
      "RMSE: 32365.866346090737\n",
      "R²: 0.17789834323877907\n"
     ]
    }
   ],
   "source": [
    "import error_metrics\n",
    "error_metrics.calculate_errors(y_svm, y_test, \"SVR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34024e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('imputer', SimpleImputer()), ('scaler', StandardScaler()), ('model', SVR(kernel='linear'))], 'transform_input': None, 'verbose': False, 'imputer': SimpleImputer(), 'scaler': StandardScaler(), 'model': SVR(kernel='linear'), 'imputer__add_indicator': False, 'imputer__copy': True, 'imputer__fill_value': None, 'imputer__keep_empty_features': False, 'imputer__missing_values': nan, 'imputer__strategy': 'mean', 'scaler__copy': True, 'scaler__with_mean': True, 'scaler__with_std': True, 'model__C': 1.0, 'model__cache_size': 200, 'model__coef0': 0.0, 'model__degree': 3, 'model__epsilon': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear', 'model__max_iter': -1, 'model__shrinking': True, 'model__tol': 0.001, 'model__verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(svm.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fad5128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'model__C': 100, 'model__degree': 2, 'model__epsilon': 1.0, 'model__gamma': 'scale', 'model__kernel': 'linear'}\n",
      "Best RMSE 3679.930938348204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "svm_opt = crear_pipeline_svm(SVR())\n",
    "param_grid = {\n",
    "    'model__kernel': ['linear','poly', 'rbf'],\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__epsilon': [0.1, 0.5, 1.0],\n",
    "    'model__degree': [2, 3, 4], \n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    svm_opt,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_model_svr= gs.best_estimator_\n",
    "print(\"Best Params: \",gs.best_params_)\n",
    "best_rmse = np.sqrt(-gs.best_score_)\n",
    "print(\"Best RMSE\", best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38de3127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR opt:\n",
      "MAE: 5134.151034395237\n",
      "MSE: 41731129.49340138\n",
      "RMSE: 6459.963582977955\n",
      "R²: 0.9672500086123523\n"
     ]
    }
   ],
   "source": [
    "y_best_svr = best_model_svr.predict(X_test)\n",
    "error_metrics.calculate_errors(y_best_svr, y_test, \"SVR opt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
