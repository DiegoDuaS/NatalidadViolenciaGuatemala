{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22faefcf",
   "metadata": {},
   "source": [
    "## Proyecto 3. Entrega 3\n",
    "### LSTM\n",
    "Diego Duarte 22075 - José Marchena 22398 - Andrés Kou 22305 - Esteban Zambrano 22119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061b56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import LSTM\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "csv_path = \"../DataFinal.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cd0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 3, 20)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "n_lags = 3  # Usaremos los 3 años previos\n",
    "X, y = LSTM.preparar_series_lstm(df, n_lags)\n",
    "\n",
    "# Revisar las dimensiones de X e y\n",
    "print(X.shape)  # Esto debería ser (n_samples, 3, n_features)\n",
    "print(y.shape)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe1d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 3, 20) (23, 3, 20)\n",
      "(91,) (23,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir en entrenamiento y prueba (sin mezclar las secuencias)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Ver las formas de los datos\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a29a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a325b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizar X_train, X_test, y_train, y_test\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n",
    "X_test_scaled = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1]))\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Convertir los datos normalizados a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).view(-1, X_train.shape[1], X_train.shape[2])\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).view(-1, X_test.shape[1], X_test.shape[2])\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Crear dataloaders\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5f212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "input_size = X_train.shape[2]  # El número de características (columnas de VI)\n",
    "hidden_size = 64  # Puedes ajustar este valor\n",
    "num_layers = 2  # Puedes ajustar este valor\n",
    "\n",
    "# Inicializar el modelo\n",
    "model = LSTM.LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "# Definir la función de pérdida (MSE) y el optimizador (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0628efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.0150\n",
      "Epoch [2/50], Loss: 0.9617\n",
      "Epoch [3/50], Loss: 0.9063\n",
      "Epoch [4/50], Loss: 0.8397\n",
      "Epoch [5/50], Loss: 0.7556\n",
      "Epoch [6/50], Loss: 0.6510\n",
      "Epoch [7/50], Loss: 0.5288\n",
      "Epoch [8/50], Loss: 0.4011\n",
      "Epoch [9/50], Loss: 0.2891\n",
      "Epoch [10/50], Loss: 0.2132\n",
      "Epoch [11/50], Loss: 0.1682\n",
      "Epoch [12/50], Loss: 0.1229\n",
      "Epoch [13/50], Loss: 0.0745\n",
      "Epoch [14/50], Loss: 0.0454\n",
      "Epoch [15/50], Loss: 0.0383\n",
      "Epoch [16/50], Loss: 0.0348\n",
      "Epoch [17/50], Loss: 0.0272\n",
      "Epoch [18/50], Loss: 0.0222\n",
      "Epoch [19/50], Loss: 0.0204\n",
      "Epoch [20/50], Loss: 0.0175\n",
      "Epoch [21/50], Loss: 0.0145\n",
      "Epoch [22/50], Loss: 0.0133\n",
      "Epoch [23/50], Loss: 0.0129\n",
      "Epoch [24/50], Loss: 0.0120\n",
      "Epoch [25/50], Loss: 0.0109\n",
      "Epoch [26/50], Loss: 0.0101\n",
      "Epoch [27/50], Loss: 0.0095\n",
      "Epoch [28/50], Loss: 0.0089\n",
      "Epoch [29/50], Loss: 0.0083\n",
      "Epoch [30/50], Loss: 0.0080\n",
      "Epoch [31/50], Loss: 0.0079\n",
      "Epoch [32/50], Loss: 0.0077\n",
      "Epoch [33/50], Loss: 0.0075\n",
      "Epoch [34/50], Loss: 0.0073\n",
      "Epoch [35/50], Loss: 0.0070\n",
      "Epoch [36/50], Loss: 0.0068\n",
      "Epoch [37/50], Loss: 0.0066\n",
      "Epoch [38/50], Loss: 0.0064\n",
      "Epoch [39/50], Loss: 0.0063\n",
      "Epoch [40/50], Loss: 0.0061\n",
      "Epoch [41/50], Loss: 0.0059\n",
      "Epoch [42/50], Loss: 0.0058\n",
      "Epoch [43/50], Loss: 0.0056\n",
      "Epoch [44/50], Loss: 0.0055\n",
      "Epoch [45/50], Loss: 0.0054\n",
      "Epoch [46/50], Loss: 0.0053\n",
      "Epoch [47/50], Loss: 0.0052\n",
      "Epoch [48/50], Loss: 0.0051\n",
      "Epoch [49/50], Loss: 0.0050\n",
      "Epoch [50/50], Loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Número de épocas\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Establecer el modelo en modo entrenamiento\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Enviar los datos a GPU si está disponible\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Reiniciar los gradientes de los optimizadores\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Hacer una predicción\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calcular la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Propagar hacia atrás (backpropagation)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualizar los parámetros\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb07bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [[ 0.56338555]\n",
      " [-0.19687498]\n",
      " [-0.7413362 ]\n",
      " [-1.0071175 ]\n",
      " [-1.0826098 ]]\n",
      "Valores reales: [[ 0.35792658]\n",
      " [-0.29539424]\n",
      " [-0.8298666 ]\n",
      " [-1.041411  ]\n",
      " [-1.0556492 ]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Establecer el modelo en modo evaluación\n",
    "with torch.no_grad():  # No necesitamos calcular los gradientes durante la evaluación\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Hacer predicción\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Almacenar las predicciones y los valores verdaderos\n",
    "        y_pred.append(outputs.cpu().numpy())\n",
    "        y_true.append(labels.cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "# Comparar las predicciones con los valores verdaderos\n",
    "print(f\"Predicciones: {y_pred[:5]}\")\n",
    "print(f\"Valores reales: {y_true[:5]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
